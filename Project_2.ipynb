{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dtuimldmtools as dtu\n",
    "from scipy import stats\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess dataset again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/\"\n",
    "seeds_dataset = \"seeds_dataset.txt\"\n",
    "dataset_file = data_path + seeds_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 8)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.loadtxt(dataset_file)\n",
    "# Validate shape of the dataset, 210 rows with 8 attributes\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['area_A',\n",
       "  'perimeter_P',\n",
       "  'compactness_C',\n",
       "  'length_of_kernel',\n",
       "  'width_of_kernel',\n",
       "  'asymmetry_coefficient',\n",
       "  'length_of_kernel_groove',\n",
       "  'class'],\n",
       " 210,\n",
       " 8,\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "        3., 3., 3., 3., 3., 3.]),\n",
       " (210,),\n",
       " ['Kama', 'Rosa', 'Canadian'],\n",
       " 3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data\n",
    "# attributeNames are not present in the dataset, just gonna hardcode based on the website\n",
    "attributeNames = [\n",
    "    \"area_A\",\n",
    "    \"perimeter_P\",\n",
    "    \"compactness_C\",\n",
    "    \"length_of_kernel\",\n",
    "    \"width_of_kernel\",\n",
    "    \"asymmetry_coefficient\",\n",
    "    \"length_of_kernel_groove\",\n",
    "    \"class\",\n",
    "]\n",
    "N = data.shape[0]\n",
    "M = data.shape[1]\n",
    "y = X[:, -1]\n",
    "# This is derived from the website\n",
    "classNames = [\"Kama\", \"Rosa\", \"Canadian\"]\n",
    "C = len(classNames)\n",
    "attributeNames, N, M, y, y.shape, classNames, C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure zero-indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((210, 8),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2.]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, -1] -= 1\n",
    "X.shape, X[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outlier as shown from project_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209, (209, 8), (209,))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribute_index = attributeNames.index(\"length_of_kernel\")\n",
    "lowest_index = np.argmin(X[:, 3])\n",
    "X_updated = np.delete(X, lowest_index, axis=0)\n",
    "y = np.delete(y, lowest_index, axis=0)\n",
    "N -= 1\n",
    "N, X_updated.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove class column because we would not need it for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209, 7)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_updated = X_updated[:, :-1]\n",
    "X_updated.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize data\n",
    "Data standardization/ data scaling needs to be done if the data have huge or scattered values, machine learning model needs smaller and coherent values. Data scaling, standardize values in the data set for better results.\"\n",
    "\n",
    "https://www.kaggle.com/discussions/questions-and-answers/159183#910328"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "X_mean = np.mean(X_updated, axis=0)\n",
    "X_std = np.std(X_updated, axis=0)\n",
    "X_standardized = (X_updated - X_mean) / X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((209, 7), (209,))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_standardized.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer fold 1/10\n",
      "Outer fold 2/10\n",
      "Outer fold 3/10\n",
      "Outer fold 4/10\n",
      "Outer fold 5/10\n",
      "Outer fold 6/10\n",
      "Outer fold 7/10\n",
      "Outer fold 8/10\n",
      "Outer fold 9/10\n",
      "Outer fold 10/10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "# data = np.loadtxt(\"seeds_dataset.txt\")\n",
    "\n",
    "# Predict 'Area' (first column), use the rest as features\n",
    "y = data[:, 0]\n",
    "X = data[:, 1:7]  # Exclude Area\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Two-level cross-validation parameters\n",
    "K1 = K2 = 10\n",
    "hidden_units = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21]\n",
    "lambdas = np.power(10.0, range(-5, 9\n",
    "))  # Regression λ values: 1e-5 to 1e5\n",
    "\n",
    "# ANN model training function\n",
    "def train_model(X_train, y_train, X_val, y_val, hidden_units, lr=0.01, max_epochs=1000):\n",
    "    M = X_train.shape[1]\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(M, hidden_units),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(hidden_units, 1)\n",
    "    )\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_train)\n",
    "        loss = criterion(output, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_val)\n",
    "        mse = mean_squared_error(y_val.numpy(), y_pred.numpy())\n",
    "    return model, mse\n",
    "\n",
    "# Statistical evaluation\n",
    "def statistically_evaluate(name1, squared_error_1, name2, squared_error_2):\n",
    "    alpha = 0.05\n",
    "    z = squared_error_1 - squared_error_2\n",
    "    CI = st.t.interval(1 - alpha, len(z) - 1, loc=np.mean(z), scale=st.sem(z))\n",
    "    p = 2 * st.t.cdf(-np.abs(np.mean(z)) / st.sem(z), df=len(z) - 1)\n",
    "    print(f\"Confidence interval of {name1}-{name2}: {CI}\")\n",
    "    print(f\"p-value: {p}\\n\")\n",
    "    return np.mean(z), CI[0], CI[1], p\n",
    "\n",
    "# Results container\n",
    "results = []\n",
    "\n",
    "outer_cv = KFold(n_splits=K1, shuffle=True, random_state=1)\n",
    "\n",
    "for outer_fold, (train_idx, test_idx) in enumerate(outer_cv.split(X)):\n",
    "    print(f\"Outer fold {outer_fold + 1}/{K1}\")\n",
    "    X_par, y_par = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "    inner_cv = KFold(n_splits=K2, shuffle=True, random_state=outer_fold)\n",
    "\n",
    "    # --- ANN ---\n",
    "    best_ann_err = np.inf\n",
    "    best_h = None\n",
    "    best_ann_model = None\n",
    "\n",
    "    for h in hidden_units:\n",
    "        ann_errs = []\n",
    "        for inner_train_idx, val_idx in inner_cv.split(X_par):\n",
    "            X_train = torch.tensor(X_par[inner_train_idx], dtype=torch.float32)\n",
    "            y_train = torch.tensor(y_par[inner_train_idx].reshape(-1, 1), dtype=torch.float32)\n",
    "            X_val = torch.tensor(X_par[val_idx], dtype=torch.float32)\n",
    "            y_val = torch.tensor(y_par[val_idx].reshape(-1, 1), dtype=torch.float32)\n",
    "            model, mse = train_model(X_train, y_train, X_val, y_val, hidden_units=h)\n",
    "            ann_errs.append(mse)\n",
    "        mean_ann_err = np.mean(ann_errs)\n",
    "        if mean_ann_err < best_ann_err:\n",
    "            best_ann_err = mean_ann_err\n",
    "            best_h = h\n",
    "            X_par_tensor = torch.tensor(X_par, dtype=torch.float32)\n",
    "            y_par_tensor = torch.tensor(y_par.reshape(-1, 1), dtype=torch.float32)\n",
    "            best_ann_model, _ = train_model(X_par_tensor, y_par_tensor, X_par_tensor, y_par_tensor, hidden_units=h)\n",
    "\n",
    "    # --- Regression (Ridge) ---\n",
    "    best_regression_err = np.inf\n",
    "    best_lambda = None\n",
    "    best_regression_model = None\n",
    "\n",
    "    for lam in lambdas:\n",
    "        regression_errs = []\n",
    "        for inner_train_idx, val_idx in inner_cv.split(X_par):\n",
    "            X_train, y_train = X_par[inner_train_idx], y_par[inner_train_idx]\n",
    "            X_val, y_val = X_par[val_idx], y_par[val_idx]\n",
    "            model = Ridge(alpha=lam)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_val_pred = model.predict(X_val)\n",
    "            regression_errs.append(mean_squared_error(y_val, y_val_pred))\n",
    "        mean_regression_err = np.mean(regression_errs)\n",
    "        if mean_regression_err < best_regression_err:\n",
    "            best_regression_err = mean_regression_err\n",
    "            best_lambda = lam\n",
    "            best_regression_model = Ridge(alpha=lam).fit(X_par, y_par)\n",
    "\n",
    "    # --- Evaluation ---\n",
    "    y_pred_baseline = np.full_like(y_test, np.mean(y_par))\n",
    "    y_pred_regression = best_regression_model.predict(X_test)\n",
    "\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    best_ann_model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_ann = best_ann_model(X_test_tensor).numpy()\n",
    "\n",
    "    ann_test_error = mean_squared_error(y_test, y_pred_ann)\n",
    "    regression_test_error = mean_squared_error(y_test, y_pred_regression)\n",
    "    baseline_test_error = mean_squared_error(y_test, y_pred_baseline)\n",
    "\n",
    "    results.append([outer_fold + 1, best_h, ann_test_error, best_lambda, regression_test_error, baseline_test_error])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final cross-validation results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outer fold</th>\n",
       "      <th>h*</th>\n",
       "      <th>ann E_test</th>\n",
       "      <th>lambda*</th>\n",
       "      <th>regression E_test</th>\n",
       "      <th>baseline E_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>10.379972</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.015133</td>\n",
       "      <td>6.275958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.099721</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.014889</td>\n",
       "      <td>10.159598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0.054595</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.010238</td>\n",
       "      <td>10.798736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>0.004206</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.005802</td>\n",
       "      <td>6.842417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0.085733</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.019104</td>\n",
       "      <td>12.788180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0.084067</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.008942</td>\n",
       "      <td>8.954705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.570766</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.013297</td>\n",
       "      <td>9.717176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>0.013464</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.009461</td>\n",
       "      <td>5.697848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0.401424</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>8.068414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>0.010761</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.021016</td>\n",
       "      <td>5.481287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Outer fold  h*  ann E_test  lambda*  regression E_test  baseline E_test\n",
       "0           1  21   10.379972     0.01           0.015133         6.275958\n",
       "1           2   7    0.099721     0.01           0.014889        10.159598\n",
       "2           3  13    0.054595     0.10           0.010238        10.798736\n",
       "3           4  19    0.004206     0.10           0.005802         6.842417\n",
       "4           5  15    0.085733     0.10           0.019104        12.788180\n",
       "5           6   9    0.084067     0.10           0.008942         8.954705\n",
       "6           7   9    0.570766     0.01           0.013297         9.717176\n",
       "7           8  19    0.013464     0.10           0.009461         5.697848\n",
       "8           9  11    0.401424     0.01           0.015283         8.068414\n",
       "9          10  19    0.010761     0.10           0.021016         5.481287"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create DataFrame\n",
    "df_results = pd.DataFrame(results, columns=[\n",
    "    \"Outer fold\", \"h*\", \"ann E_test\", \"lambda*\", \"regression E_test\", \"baseline E_test\"\n",
    "])\n",
    "print(\"\\nFinal cross-validation results:\")\n",
    "#print(df_results)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistical evaluation summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comparison</th>\n",
       "      <th>p-value</th>\n",
       "      <th>lower bound</th>\n",
       "      <th>upper bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ann vs regr</td>\n",
       "      <td>0.288030</td>\n",
       "      <td>-1.161101</td>\n",
       "      <td>3.475410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ann vs base</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>-10.602554</td>\n",
       "      <td>-4.013368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>regr vs base</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-10.199907</td>\n",
       "      <td>-6.730324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     comparison   p-value  lower bound  upper bound\n",
       "0   ann vs regr  0.288030    -1.161101     3.475410\n",
       "1   ann vs base  0.000721   -10.602554    -4.013368\n",
       "2  regr vs base  0.000002   -10.199907    -6.730324"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistical evaluation table\n",
    "diff_results = []\n",
    "comparisons = [\n",
    "    (\"ann vs regr\", df_results[\"ann E_test\"].values, df_results[\"regression E_test\"].values),\n",
    "    (\"ann vs base\", df_results[\"ann E_test\"].values, df_results[\"baseline E_test\"].values),\n",
    "    (\"regr vs base\", df_results[\"regression E_test\"].values, df_results[\"baseline E_test\"].values)\n",
    "]\n",
    "\n",
    "for label, err1, err2 in comparisons:\n",
    "    z = err1 - err2\n",
    "    ci = st.t.interval(0.95, len(z) - 1, loc=np.mean(z), scale=st.sem(z))\n",
    "    p = 2 * st.t.cdf(-np.abs(np.mean(z)) / st.sem(z), df=len(z) - 1)\n",
    "    diff_results.append([label, p, ci[0], ci[1]])\n",
    "\n",
    "df_stat_eval = pd.DataFrame(diff_results, columns=[\n",
    "    \"comparison\", \"p-value\", \"lower bound\", \"upper bound\"\n",
    "])\n",
    "\n",
    "\n",
    "print(\"\\nStatistical evaluation summary:\")\n",
    "#print(df_stat_eval)\n",
    "df_stat_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "3 models would be implemented\n",
    "* Baseline model: majority model\n",
    "* Logistic regression with a softmax activation function at the end\n",
    "* ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "CV = model_selection.KFold(K, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model\n",
    "Majority class classifier : where the most frequent class in the data is predicted for all observations. For instance, if we have 80% of observations in class A and 20% in class B for a binary classification problem, the baseline model would predict Class A for all instances.\n",
    "https://medium.com/@preethi_prakash/understanding-baseline-models-in-machine-learning-3ed94f03d645"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([10.59, 10.74, 10.79, 10.8 , 10.82, 10.83, 10.91, 10.93, 11.02,\n",
       "        11.14, 11.18, 11.19, 11.21, 11.23, 11.24, 11.26, 11.27, 11.34,\n",
       "        11.35, 11.36, 11.4 , 11.41, 11.42, 11.43, 11.48, 11.49, 11.55,\n",
       "        11.56, 11.65, 11.75, 11.81, 11.82, 11.83, 11.84, 11.87, 12.01,\n",
       "        12.02, 12.05, 12.08, 12.1 , 12.11, 12.13, 12.15, 12.19, 12.21,\n",
       "        12.22, 12.26, 12.3 , 12.36, 12.37, 12.38, 12.44, 12.46, 12.49,\n",
       "        12.54, 12.55, 12.62, 12.67, 12.7 , 12.72, 12.73, 12.74, 12.76,\n",
       "        12.78, 12.79, 12.8 , 12.88, 12.89, 13.02, 13.07, 13.16, 13.2 ,\n",
       "        13.22, 13.32, 13.34, 13.37, 13.45, 13.5 , 13.54, 13.74, 13.78,\n",
       "        13.8 , 13.84, 13.89, 13.94, 13.99, 14.01, 14.03, 14.09, 14.11,\n",
       "        14.16, 14.28, 14.29, 14.33, 14.34, 14.37, 14.38, 14.43, 14.46,\n",
       "        14.49, 14.52, 14.59, 14.69, 14.7 , 14.79, 14.8 , 14.86, 14.88,\n",
       "        14.92, 14.99, 15.01, 15.03, 15.05, 15.11, 15.26, 15.36, 15.38,\n",
       "        15.49, 15.5 , 15.56, 15.57, 15.6 , 15.69, 15.78, 15.88, 15.99,\n",
       "        16.12, 16.14, 16.16, 16.17, 16.19, 16.2 , 16.23, 16.41, 16.44,\n",
       "        16.53, 16.63, 16.77, 16.82, 16.84, 16.87, 17.08, 17.12, 17.26,\n",
       "        17.32, 17.36, 17.55, 17.63, 17.98, 17.99, 18.14, 18.17, 18.27,\n",
       "        18.3 , 18.36, 18.43, 18.45, 18.55, 18.59, 18.65, 18.72, 18.75,\n",
       "        18.76, 18.81, 18.83, 18.85, 18.88, 18.89, 18.94, 18.95, 18.96,\n",
       "        18.98, 19.06, 19.11, 19.13, 19.14, 19.15, 19.18, 19.31, 19.38,\n",
       "        19.46, 19.51, 19.57, 19.94, 20.03, 20.1 , 20.16, 20.2 , 20.24,\n",
       "        20.71, 20.88, 20.97, 21.18]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y, return_counts=True)\n",
    "unique, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [209, 210]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m baseline_error_rates \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_index, test_index \u001b[38;5;129;01min\u001b[39;00m CV\u001b[38;5;241m.\u001b[39msplit(X_standardized, y):\n\u001b[1;32m      3\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m X_standardized[train_index]\n\u001b[1;32m      4\u001b[0m     y_train \u001b[38;5;241m=\u001b[39m y[train_index]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_split.py:406\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    383\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \n\u001b[1;32m    385\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;124;03m        The testing set indices for that split.\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 406\u001b[0m     X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m    407\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:514\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \n\u001b[1;32m    486\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;124;03m[[1, 2, 3], array([2, 3, 4]), None, <3x1 sparse matrix ...>]\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    513\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[0;32m--> 514\u001b[0m check_consistent_length(\u001b[38;5;241m*\u001b[39mresult)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    460\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [209, 210]"
     ]
    }
   ],
   "source": [
    "baseline_error_rates = []\n",
    "for train_index, test_index in CV.split(X_standardized, y):\n",
    "    X_train = X_standardized[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X_standardized[test_index]\n",
    "    y_test = y[test_index]\n",
    "    baseline = DummyClassifier(strategy='most_frequent')\n",
    "    baseline.fit(X_train, y_train)\n",
    "    y_preds = baseline.predict(X_test)\n",
    "\n",
    "    e = y_preds != y_test\n",
    "    error_rate = sum(e) / len(e)\n",
    "    baseline_error_rates.append(error_rate)\n",
    "    print(\n",
    "        f\"Number of miss-classifications for baseline model:\\n\\t {sum(e)} out of {len(e)}. Overall error_rate {error_rate}\"\n",
    "    )\n",
    "mean_error_rate = np.mean(np.asarray(baseline_error_rates))\n",
    "print(f\"mean_error_rate for baseline model is {mean_error_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "Add an extra variable lambda to penalise large weights\n",
    "Testing the range of lambda from 10^-5 to 10^4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = np.power(10.0, range(-5, 5))\n",
    "lambdas.shape, lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtuimldmtools import rlr_validate\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rates_and_lambda = []\n",
    "yhat_log = []\n",
    "y_true_log = []\n",
    "lambdas = np.power(10.0, range(-5, 5))\n",
    "for train_index, test_index in CV.split(X_standardized, y):\n",
    "    X_train = X_standardized[train_index]\n",
    "    y_train = y[train_index].astype(np.int64)\n",
    "    X_test = X_standardized[test_index]\n",
    "    y_test = y[test_index].astype(np.int64)\n",
    "    internal_cross_validation = 10\n",
    "    input_features = M - 1\n",
    "    # One-hot encoding\n",
    "    Y_train = np.zeros((len(y_train), C))\n",
    "    for i, label in enumerate(y_train):\n",
    "        Y_train[i, label] = 1\n",
    "    # Function returns:\n",
    "    # MSE averaged over 'cvf' folds,\n",
    "    # optimal value of lambda,\n",
    "    # average weight values for all lambdas,\n",
    "    # MSE train&validation errors for all lambdas.\n",
    "    # The cross validation splits are standardized based on the mean and standard deviation of the training set when estimating the regularization strength.\n",
    "    _, opt_lambda, _, _, _, = rlr_validate(X_train, y_train, lambdas, internal_cross_validation)\n",
    "    Xty = X_train.T @ Y_train\n",
    "    XtX = X_train.T @ X_train\n",
    "    # Estimate weights for the optimal value of lambda, on entire training set\n",
    "    lambdaI = opt_lambda * np.eye(input_features)\n",
    "    lambdaI[0, 0] = 0  # Do no regularize the bias term\n",
    "    # Recall: Introduce regularization term λ‖w‖2 to penalize large weights, remove the significance of these weight\n",
    "    # Recall: (X^T@X + lambdaI) @ w = X^T @ y\n",
    "    estimated_weights = np.linalg.solve(XtX + lambdaI, Xty).squeeze()\n",
    "    prediction_logits = X_test @ estimated_weights\n",
    "    predicted_class = np.argmax(softmax(prediction_logits), axis=1)\n",
    "    yhat_log.append(predicted_class)\n",
    "    y_true_log.append(y_test)\n",
    "    e = predicted_class != y_test\n",
    "    error_rate = sum(e) / len(e)\n",
    "    error_rates_and_lambda.append((error_rate, opt_lambda))\n",
    "    print(\n",
    "        f\"Number of miss-classifications for logic regression model with optimal lambda value {opt_lambda}:\\n\\t {sum(e)} out of {len(e)}. Overall error_rate {error_rate}\"\n",
    "    )\n",
    "\n",
    "error_rates_and_lambda, len(error_rates_and_lambda)\n",
    "yhat_log = np.concatenate(yhat_log)\n",
    "y_true_log = np.concatenate(y_true_log)\n",
    "yhat_log.shape, y_true_log.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass ANN\n",
    "Since we have three distinct classes: Kama, Rosa and Canadian, we adopt a multiclass approach. \n",
    "As complexity-controlling parameter\n",
    "for the ANN, we will use the number of hidden units3 h. Based on a few test-runs, select\n",
    "a reasonable range of values for h (which should include h = 1), and describe the range of\n",
    "values you will use for h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from dtuimldmtools import dbplotf, train_neural_net, visualize_decision_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rates = []\n",
    "for train_index, test_index in CV.split(X_standardized, y):\n",
    "    X_train = torch.from_numpy(X_standardized[train_index]).type(torch.float)\n",
    "    y_train = torch.from_numpy(y[train_index]).type(torch.long)\n",
    "    X_test = torch.from_numpy(X_standardized[test_index]).type(torch.float)\n",
    "    y_test = torch.from_numpy(y[test_index]).type(torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN training and mean_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_units_range = 10\n",
    "initial_hidden_units = 2\n",
    "error_rates_and_hidden_units_in_folds = []\n",
    "for train_index, test_index in CV.split(X_standardized, y):\n",
    "    X_train = torch.from_numpy(X_standardized[train_index]).type(torch.float)\n",
    "    y_train = torch.from_numpy(y[train_index]).type(torch.long)\n",
    "    X_test = torch.from_numpy(X_standardized[test_index]).type(torch.float)\n",
    "    y_test = torch.from_numpy(y[test_index]).type(torch.long)\n",
    "    error_rates_and_hidden_units = []\n",
    "    for n_hidden_units in range(\n",
    "        initial_hidden_units, initial_hidden_units + hidden_units_range\n",
    "    ):\n",
    "        # in the actual code, we would vary the number of hidden_units here\n",
    "        # e.g. for i in range (100) -> calculate mean_error_rate\n",
    "        # Recall that last column represents the classes and should not be used as an input feature\n",
    "        input_features = M - 1\n",
    "        num_epochs = 300\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        seed_model = lambda: torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_features, n_hidden_units),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(n_hidden_units, C),\n",
    "            torch.nn.Softmax(dim=1),\n",
    "        )\n",
    "        net, final_loss, learning_curve = train_neural_net(\n",
    "            seed_model,\n",
    "            loss_fn,\n",
    "            X=X_train,\n",
    "            y=y_train,\n",
    "            n_replicates=3,\n",
    "            max_iter=num_epochs,\n",
    "        )\n",
    "        print(\"\\n\\t model loss: {}\\n\".format(final_loss))\n",
    "\n",
    "        # Determine probability of each class using trained network\n",
    "        softmax_logits = net(X_test)\n",
    "        # convert to label with the highest probability# Parametergrids\n",
    "lambda_values = np.logspace(-5, 2, 10)\n",
    "hidden_units = [1, 2, 4, 8, 16]\n",
    "\n",
    "# Outer K-fold\n",
    "K1 = 10\n",
    "outer_cv = KFold(n_splits=K1, shuffle=True, random_state=1)\n",
    "\n",
    "# Ergebnisse speichern\n",
    "results = []\n",
    "y_pred = torch.argmax(softmax_logits, dim=1)\n",
    "# Compare error against ground truth y_test\n",
    "e = y_pred != y_test\n",
    "error_rate = sum(e) / len(e)\n",
    "error_rates_and_hidden_units.append((error_rate, n_hidden_units))\n",
    "print(\n",
    "    f\"Number of miss-classifications for ANN:\\n\\t {sum(e)} out of {len(e)}. Overall error_rate {error_rate}\"\n",
    ")\n",
    "\n",
    "smallest_error_rate, num_hidden_units = min(\n",
    "error_rates_and_hidden_units, key=itemgetter(0)\n",
    ")\n",
    "error_rates_and_hidden_units_in_folds.append(\n",
    "(smallest_error_rate, num_hidden_units)\n",
    ")\n",
    "print(\n",
    "f\"smallest_error_rate for {num_hidden_units} hidden_units is {smallest_error_rate}\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot comparison table between the 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_error_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rates_and_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rates_and_hidden_units_in_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "\n",
    "error_rates_from_lambda = [rate for rate, _ in error_rates_and_lambda]\n",
    "lambda_values = [lmbda for _, lmbda in error_rates_and_lambda]\n",
    "\n",
    "error_rates_from_hidden_units = [\n",
    "    rate.item() if hasattr(rate, \"item\") else float(rate)\n",
    "    for rate, _ in error_rates_and_hidden_units_in_folds\n",
    "]\n",
    "hidden_units = [units for _, units in error_rates_and_hidden_units_in_folds]\n",
    "error_rates_from_lambda, error_rates_from_hidden_units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_folds = len(baseline_error_rates)\n",
    "\n",
    "table_data = [\n",
    "    [\n",
    "        fold + 1,\n",
    "        hidden_units[fold],\n",
    "        error_rates_from_hidden_units[fold],\n",
    "        lambda_values[fold],\n",
    "        error_rates_from_lambda[fold],\n",
    "        baseline_error_rates[fold],\n",
    "    ]\n",
    "    for fold in range(num_folds)\n",
    "]\n",
    "\n",
    "# Column headers (as shown in the image)\n",
    "col_labels = [\"i\", \"x_t^*\", \"E_t^NN\", \"λ_t^*\", \"E_t^λ\", \"E_t^baseline\"]\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.axis(\"off\")\n",
    "\n",
    "# Plot the table\n",
    "table = ax.table(\n",
    "    cellText=table_data, colLabels=col_labels, loc=\"center\", cellLoc=\"center\"\n",
    ")\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "table.scale(3, 3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of models using mc neymar test\n",
    "![mc_neymar](museum_of_poor/mc_neymar.png)\n",
    "Perform a statistical evaluation of your three models similar to the previous section. That\n",
    "is, compare the three models pairwise. We will once more allow some freedom in what test\n",
    "to choose. Therefore, choose either:\n",
    "setup I (section 11.3): Use McNemar’s test described in Box 11.3.2)\n",
    "setup II (section 11.4): Use the method described in Box 11.4.1)\n",
    "Include p-values and confidence intervals for the three pairwise tests in your report and\n",
    "conclude on the results: Is one model better than the other? Are the two models better\n",
    "than the baseline? Are some of the models identical? What recommendations would you\n",
    "make based on what you’ve learned?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To ensure a fair comparison, we need to perform the train and test on the same split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_dummy = []\n",
    "yhat_log = []\n",
    "yhat_ann = []\n",
    "y_true = []\n",
    "lambdas = np.power(10.0, range(-5, 5))\n",
    "for train_index, test_index in CV.split(X_standardized, y):\n",
    "    X_train = X_standardized[train_index]\n",
    "    y_train = y[train_index].astype(np.int64)\n",
    "    X_test = X_standardized[test_index]\n",
    "    y_test = y[test_index].astype(np.int64)\n",
    "    internal_cross_validation = 10\n",
    "    input_features = M - 1\n",
    "    y_true.append(y_test)\n",
    "\n",
    "    # One-hot encoding\n",
    "    Y_train_hot = np.zeros((len(y_train), C))\n",
    "    for i, label in enumerate(y_train):\n",
    "        Y_train_hot[i, label] = 1\n",
    "\n",
    "    # Dummy classifier\n",
    "    baseline = DummyClassifier(strategy='most_frequent')\n",
    "    baseline.fit(X_train, y_train)\n",
    "    y_dummy_pred = baseline.predict(X_test)\n",
    "    yhat_dummy.append(y_dummy_pred)\n",
    "    (\n",
    "        _,\n",
    "        opt_lambda,\n",
    "        _,\n",
    "        _,\n",
    "        _,\n",
    "    ) = rlr_validate(X_train, y_train, lambdas, internal_cross_validation)\n",
    "    Xty = X_train.T @ Y_train_hot\n",
    "    XtX = X_train.T @ X_train\n",
    "    # Estimate weights for the optimal value of lambda, on entire training set\n",
    "    lambdaI = opt_lambda * np.eye(input_features)\n",
    "    lambdaI[0, 0] = 0  # Do no regularize the bias term\n",
    "    # Recall: Introduce regularization term λ‖w‖2 to penalize large weights, remove the significance of these weight\n",
    "    # Recall: (X^T@X + lambdaI) @ w = X^T @ y\n",
    "    estimated_weights = np.linalg.solve(XtX + lambdaI, Xty).squeeze()\n",
    "    prediction_logits = X_test @ estimated_weights\n",
    "    predicted_class = np.argmax(softmax(prediction_logits), axis=1)\n",
    "    yhat_log.append(predicted_class)\n",
    "\n",
    "    X_train_tensor = torch.from_numpy(X_standardized[train_index]).type(torch.float)\n",
    "    y_train_tensor = torch.from_numpy(y[train_index]).type(torch.long)\n",
    "    X_test_tensor = torch.from_numpy(X_standardized[test_index]).type(torch.float)\n",
    "    y_test_tensor = torch.from_numpy(y[test_index]).type(torch.long)\n",
    "    error_rates_and_hidden_units = []\n",
    "    input_features = M - 1\n",
    "    num_epochs = 300\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    seed_model = lambda: torch.nn.Sequential(\n",
    "        torch.nn.Linear(input_features, n_hidden_units),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(n_hidden_units, C),\n",
    "        torch.nn.Softmax(dim=1),\n",
    "    )\n",
    "    for n_hidden_units in range(\n",
    "        initial_hidden_units, initial_hidden_units + hidden_units_range\n",
    "    ):\n",
    "        # in the actual code, we would vary the number of hidden_units here\n",
    "        # e.g. for i in range (100) -> calculate mean_error_rate\n",
    "        # Recall that last column represents the classes and should not be used as an input feature\n",
    "\n",
    "        net, final_loss, learning_curve = train_neural_net(\n",
    "            seed_model,\n",
    "            loss_fn,\n",
    "            X=X_train_tensor,\n",
    "            y=y_train_tensor,\n",
    "            n_replicates=3,\n",
    "            max_iter=num_epochs,\n",
    "        )\n",
    "\n",
    "        # Determine probability of each class using trained network\n",
    "        softmax_logits = net(X_test_tensor)\n",
    "        # convert to label with the highest probability\n",
    "        y_preds = torch.argmax(softmax_logits, dim=1)\n",
    "        # Compare error against ground truth y_test\n",
    "        e = y_preds != y_test\n",
    "        error_rate = sum(e) / len(e)\n",
    "        error_rates_and_hidden_units.append((error_rate, n_hidden_units, y_pred))\n",
    "\n",
    "\n",
    "    _, _, best_pred = min(\n",
    "        error_rates_and_hidden_units, key=itemgetter(0)\n",
    "    )\n",
    "    yhat_ann.append(best_pred)\n",
    "yhat_dummy = np.concatenate(yhat_dummy)\n",
    "yhat_log = np.concatenate(yhat_log)\n",
    "yhat_ann= np.concatenate(yhat_ann)\n",
    "y_true = np.concatenate(y_true)\n",
    "yhat_dummy.shape, yhat_log.shape, y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtuimldmtools import mcnemar\n",
    "\n",
    "# Compute the Jeffreys interval\n",
    "alpha = 0.05\n",
    "[thetahat, CI, p] = mcnemar(y_true_dummy, yhat[:, 0], yhat[:, 1], alpha=alpha)\n",
    "\n",
    "print(\"theta = theta_A-theta_B point estimate\", thetahat, \" CI: \", CI, \"p-value\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final regression model with $\\lambda$ = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rates = []\n",
    "for train_index, test_index in CV.split(X_standardized, y):\n",
    "    X_train = X_standardized[train_index]\n",
    "    y_train = y[train_index].astype(np.int64)\n",
    "    X_test = X_standardized[test_index]\n",
    "    y_test = y[test_index].astype(np.int64)\n",
    "    internal_cross_validation = 10\n",
    "    input_features = M - 1\n",
    "    # One-hot encoding\n",
    "    Y_train = np.zeros((len(y_train), C))\n",
    "    for i, label in enumerate(y_train):\n",
    "        Y_train[i, label] = 1\n",
    "    opt_lambda = 0.01\n",
    "    Xty = X_train.T @ Y_train\n",
    "    XtX = X_train.T @ X_train\n",
    "    # Estimate weights for the optimal value of lambda, on entire training set\n",
    "    lambdaI = opt_lambda * np.eye(input_features)\n",
    "    lambdaI[0, 0] = 0  # Do no regularize the bias term\n",
    "    # Recall: Introduce regularization term λ‖w‖2 to penalize large weights, remove the significance of these weight\n",
    "    # Recall: (X^T@X + lambdaI) @ w = X^T @ y\n",
    "    estimated_weights = np.linalg.solve(XtX + lambdaI, Xty).squeeze()\n",
    "    prediction_logits = X_test @ estimated_weights\n",
    "    predicted_classes = np.argmax(softmax(prediction_logits), axis=1)\n",
    "    e = predicted_classes != y_test\n",
    "    error_rate = sum(e) / len(e)\n",
    "    error_rates.append(error_rate)\n",
    "    print(\n",
    "        f\"Number of miss-classifications for logic regression model with optimal lambda value {opt_lambda}:\\n\\t {sum(e)} out of {len(e)}. Overall error_rate {error_rate}\"\n",
    "    )\n",
    "error_rates, len(error_rates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
