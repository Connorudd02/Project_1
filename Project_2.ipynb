{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dtuimldmtools as dtu\n",
    "from scipy import stats\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess dataset again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/\"\n",
    "seeds_dataset = \"seeds_dataset.txt\"\n",
    "dataset_file = data_path + seeds_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 8)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.loadtxt(dataset_file)\n",
    "# Validate shape of the dataset, 210 rows with 8 attributes\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['area_A',\n",
       "  'perimeter_P',\n",
       "  'compactness_C',\n",
       "  'length_of_kernel',\n",
       "  'width_of_kernel',\n",
       "  'asymmetry_coefficient',\n",
       "  'length_of_kernel_groove',\n",
       "  'class'],\n",
       " 210,\n",
       " 8,\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "        3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "        3., 3., 3., 3., 3., 3.]),\n",
       " (210,),\n",
       " ['Kama', 'Rosa', 'Canadian'],\n",
       " 3)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data\n",
    "# attributeNames are not present in the dataset, just gonna hardcode based on the website\n",
    "attributeNames = [\n",
    "    \"area_A\",\n",
    "    \"perimeter_P\",\n",
    "    \"compactness_C\",\n",
    "    \"length_of_kernel\",\n",
    "    \"width_of_kernel\",\n",
    "    \"asymmetry_coefficient\",\n",
    "    \"length_of_kernel_groove\",\n",
    "    \"class\",\n",
    "]\n",
    "N = data.shape[0]\n",
    "M = data.shape[1]\n",
    "y = X[:, -1]\n",
    "# This is derived from the website\n",
    "classNames = [\"Kama\", \"Rosa\", \"Canadian\"]\n",
    "C = len(classNames)\n",
    "attributeNames, N, M, y, y.shape, classNames, C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure zero-indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((210, 8),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2., 2., 2., 2.]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, -1] -= 1\n",
    "X.shape, X[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outlier as shown from project_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209, (209, 8), (209,))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribute_index = attributeNames.index(\"length_of_kernel\")\n",
    "lowest_index = np.argmin(X[:, 3])\n",
    "X_updated = np.delete(X, lowest_index, axis=0)\n",
    "y = np.delete(y, lowest_index, axis=0)\n",
    "N -= 1\n",
    "N, X_updated.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove class column because we would not need it for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209, 7)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_updated = X_updated[:, :-1]\n",
    "X_updated.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize data\n",
    "Data standardization/ data scaling needs to be done if the data have huge or scattered values, machine learning model needs smaller and coherent values. Data scaling, standardize values in the data set for better results.\"\n",
    "\n",
    "https://www.kaggle.com/discussions/questions-and-answers/159183#910328"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "X_mean = np.mean(X_updated, axis=0)\n",
    "X_std = np.std(X_updated, axis=0)\n",
    "X_standardized = (X_updated - X_mean) / X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((209, 7), (209,))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_standardized.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- WORK IN PROGRESS --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "3 models would be implemented\n",
    "* Baseline model: majority model\n",
    "* Logistic regression with a softmax activation function at the end\n",
    "* ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "CV = model_selection.KFold(K, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model\n",
    "Majority class classifier : where the most frequent class in the data is predicted for all observations. For instance, if we have 80% of observations in class A and 20% in class B for a binary classification problem, the baseline model would predict Class A for all instances.\n",
    "https://medium.com/@preethi_prakash/understanding-baseline-models-in-machine-learning-3ed94f03d645"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 2.]), array([69, 70, 70]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y, return_counts=True)\n",
    "unique, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of miss-classifications for baseline model:\n",
      "\t 14 out of 21. Overall error_rate 0.6666666666666666\n",
      "Number of miss-classifications for baseline model:\n",
      "\t 15 out of 21. Overall error_rate 0.7142857142857143\n",
      "Number of miss-classifications for baseline model:\n",
      "\t 16 out of 21. Overall error_rate 0.7619047619047619\n",
      "Number of miss-classifications for baseline model:\n",
      "\t 15 out of 21. Overall error_rate 0.7142857142857143\n",
      "Number of miss-classifications for baseline model:\n",
      "\t 15 out of 21. Overall error_rate 0.7142857142857143\n",
      "Number of miss-classifications for baseline model:\n",
      "\t 18 out of 21. Overall error_rate 0.8571428571428571\n",
      "Number of miss-classifications for baseline model:\n",
      "\t 17 out of 21. Overall error_rate 0.8095238095238095\n",
      "Number of miss-classifications for baseline model:\n",
      "\t 17 out of 21. Overall error_rate 0.8095238095238095\n",
      "Number of miss-classifications for baseline model:\n",
      "\t 15 out of 21. Overall error_rate 0.7142857142857143\n",
      "Number of miss-classifications for baseline model:\n",
      "\t 15 out of 20. Overall error_rate 0.75\n",
      "mean_error_rate for baseline model is 0.7511904761904762\n"
     ]
    }
   ],
   "source": [
    "baseline_error_rates = []\n",
    "for train_index, test_index in CV.split(X_standardized, y):\n",
    "    X_train = X_standardized[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X_standardized[test_index]\n",
    "    y_test = y[test_index]\n",
    "    baseline = DummyClassifier(strategy='most_frequent')\n",
    "    baseline.fit(X_train, y_train)\n",
    "    y_preds = baseline.predict(X_test)\n",
    "\n",
    "    e = y_preds != y_test\n",
    "    error_rate = sum(e) / len(e)\n",
    "    baseline_error_rates.append(error_rate)\n",
    "    print(\n",
    "        f\"Number of miss-classifications for baseline model:\\n\\t {sum(e)} out of {len(e)}. Overall error_rate {error_rate}\"\n",
    "    )\n",
    "mean_error_rate = np.mean(np.asarray(baseline_error_rates))\n",
    "print(f\"mean_error_rate for baseline model is {mean_error_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "Add an extra variable lambda to penalise large weights\n",
    "Testing the range of lambda from 10^-5 to 10^4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10,),\n",
       " array([1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02,\n",
       "        1.e+03, 1.e+04]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas = np.power(10.0, range(-5, 5))\n",
    "lambdas.shape, lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtuimldmtools import rlr_validate\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of miss-classifications for logic regression model with optimal lambda value 9.999999999999999e-06:\n",
      "\t 1 out of 21. Overall error_rate 0.047619047619047616\n",
      "Number of miss-classifications for logic regression model with optimal lambda value 0.1:\n",
      "\t 0 out of 21. Overall error_rate 0.0\n",
      "Number of miss-classifications for logic regression model with optimal lambda value 9.999999999999999e-06:\n",
      "\t 0 out of 21. Overall error_rate 0.0\n",
      "Number of miss-classifications for logic regression model with optimal lambda value 0.01:\n",
      "\t 0 out of 21. Overall error_rate 0.0\n",
      "Number of miss-classifications for logic regression model with optimal lambda value 0.1:\n",
      "\t 1 out of 21. Overall error_rate 0.047619047619047616\n",
      "Number of miss-classifications for logic regression model with optimal lambda value 0.01:\n",
      "\t 1 out of 21. Overall error_rate 0.047619047619047616\n",
      "Number of miss-classifications for logic regression model with optimal lambda value 0.01:\n",
      "\t 1 out of 21. Overall error_rate 0.047619047619047616\n",
      "Number of miss-classifications for logic regression model with optimal lambda value 9.999999999999999e-06:\n",
      "\t 1 out of 21. Overall error_rate 0.047619047619047616\n",
      "Number of miss-classifications for logic regression model with optimal lambda value 0.01:\n",
      "\t 1 out of 21. Overall error_rate 0.047619047619047616\n",
      "Number of miss-classifications for logic regression model with optimal lambda value 0.1:\n",
      "\t 0 out of 20. Overall error_rate 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((209,), (209,))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_rates_and_lambda = []\n",
    "yhat_log = []\n",
    "y_true_log = []\n",
    "lambdas = np.power(10.0, range(-5, 5))\n",
    "for train_index, test_index in CV.split(X_standardized, y):\n",
    "    X_train = X_standardized[train_index]\n",
    "    y_train = y[train_index].astype(np.int64)\n",
    "    X_test = X_standardized[test_index]\n",
    "    y_test = y[test_index].astype(np.int64)\n",
    "    internal_cross_validation = 10\n",
    "    input_features = M - 1\n",
    "    # One-hot encoding\n",
    "    Y_train = np.zeros((len(y_train), C))\n",
    "    for i, label in enumerate(y_train):\n",
    "        Y_train[i, label] = 1\n",
    "    # Function returns:\n",
    "    # MSE averaged over 'cvf' folds,\n",
    "    # optimal value of lambda,\n",
    "    # average weight values for all lambdas,\n",
    "    # MSE train&validation errors for all lambdas.\n",
    "    # The cross validation splits are standardized based on the mean and standard deviation of the training set when estimating the regularization strength.\n",
    "    _, opt_lambda, _, _, _, = rlr_validate(X_train, y_train, lambdas, internal_cross_validation)\n",
    "    Xty = X_train.T @ Y_train\n",
    "    XtX = X_train.T @ X_train\n",
    "    # Estimate weights for the optimal value of lambda, on entire training set\n",
    "    lambdaI = opt_lambda * np.eye(input_features)\n",
    "    lambdaI[0, 0] = 0  # Do no regularize the bias term\n",
    "    # Recall: Introduce regularization term λ‖w‖2 to penalize large weights, remove the significance of these weight\n",
    "    # Recall: (X^T@X + lambdaI) @ w = X^T @ y\n",
    "    estimated_weights = np.linalg.solve(XtX + lambdaI, Xty).squeeze()\n",
    "    prediction_logits = X_test @ estimated_weights\n",
    "    predicted_class = np.argmax(softmax(prediction_logits), axis=1)\n",
    "    yhat_log.append(predicted_class)\n",
    "    y_true_log.append(y_test)\n",
    "    e = predicted_class != y_test\n",
    "    error_rate = sum(e) / len(e)\n",
    "    error_rates_and_lambda.append((error_rate, opt_lambda))\n",
    "    print(\n",
    "        f\"Number of miss-classifications for logic regression model with optimal lambda value {opt_lambda}:\\n\\t {sum(e)} out of {len(e)}. Overall error_rate {error_rate}\"\n",
    "    )\n",
    "\n",
    "error_rates_and_lambda, len(error_rates_and_lambda)\n",
    "yhat_log = np.concatenate(yhat_log)\n",
    "y_true_log = np.concatenate(y_true_log)\n",
    "yhat_log.shape, y_true_log.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass ANN\n",
    "Since we have three distinct classes: Kama, Rosa and Canadian, we adopt a multiclass approach. \n",
    "As complexity-controlling parameter\n",
    "for the ANN, we will use the number of hidden units3 h. Based on a few test-runs, select\n",
    "a reasonable range of values for h (which should include h = 1), and describe the range of\n",
    "values you will use for h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from dtuimldmtools import dbplotf, train_neural_net, visualize_decision_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: nvidia-smi: command not found\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rates = []\n",
    "for train_index, test_index in CV.split(X_standardized, y):\n",
    "    X_train = torch.from_numpy(X_standardized[train_index]).type(torch.float)\n",
    "    y_train = torch.from_numpy(y[train_index]).type(torch.long)\n",
    "    X_test = torch.from_numpy(X_standardized[test_index]).type(torch.float)\n",
    "    y_test = torch.from_numpy(y[test_index]).type(torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN training and mean_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t1.0132357\t0.00041466922\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.9630825\t0.0010778795\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/monkescripts/anaconda3/envs/dtu-ml/lib/python3.11/site-packages/dtuimldmtools/models/nn_trainer.py:141: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tFinal loss:\n",
      "\t\t300\t0.7774375\t0.00041628766\n",
      "\n",
      "\t model loss: 0.7774375081062317\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 1 out of 21. Overall error_rate 0.0476190485060215\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.89324796\t0.00051367504\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.91590816\t0.0004835492\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.9349099\t0.0006106493\n",
      "\n",
      "\t model loss: 0.8932479619979858\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 11 out of 21. Overall error_rate 0.523809552192688\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7809718\t0.00034691175\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.83813274\t0.0009201048\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8701883\t0.0008243573\n",
      "\n",
      "\t model loss: 0.7809718251228333\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 3 out of 21. Overall error_rate 0.1428571492433548\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.71472955\t0.0006654634\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.88703805\t0.00089826336\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6938344\t0.000549154\n",
      "\n",
      "\t model loss: 0.6938344240188599\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 3 out of 21. Overall error_rate 0.1428571492433548\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.81361383\t0.00043862974\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7371346\t0.0009453283\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.80622363\t0.0005572743\n",
      "\n",
      "\t model loss: 0.737134575843811\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 2 out of 21. Overall error_rate 0.095238097012043\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6868373\t0.00044351607\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7348449\t0.00067552965\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.77144945\t0.0013369494\n",
      "\n",
      "\t model loss: 0.6868373155593872\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 3 out of 21. Overall error_rate 0.1428571492433548\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7591974\t0.0009151388\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.74542344\t0.0010233293\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6948791\t0.0006413719\n",
      "\n",
      "\t model loss: 0.6948791146278381\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 4 out of 21. Overall error_rate 0.190476194024086\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7816444\t0.0007444611\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6828752\t0.00043222212\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.67137355\t0.0005058796\n",
      "\n",
      "\t model loss: 0.6713735461235046\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 2 out of 21. Overall error_rate 0.095238097012043\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6686451\t0.00040623522\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6680277\t0.00044833202\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.71380204\t0.0008479219\n",
      "\n",
      "\t model loss: 0.6680276989936829\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 3 out of 21. Overall error_rate 0.1428571492433548\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7265073\t0.0012397676\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6628035\t0.0003089873\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.69932336\t0.0006452149\n",
      "\n",
      "\t model loss: 0.6628034710884094\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 4 out of 21. Overall error_rate 0.190476194024086\n",
      "smallest_error_rate for 2 hidden_units is 0.0476190485060215\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t1.0235727\t0.0002354346\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8065441\t0.00038664974\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.96315247\t0.00058311113\n",
      "\n",
      "\t model loss: 0.8065441250801086\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 5 out of 21. Overall error_rate 0.2380952388048172\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.85593104\t0.0006796147\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8729593\t0.00083708\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.78524244\t0.0006037714\n",
      "\n",
      "\t model loss: 0.7852424383163452\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 3 out of 21. Overall error_rate 0.1428571492433548\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6934735\t0.00060489983\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7547684\t0.00032627973\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.85255784\t0.0006384546\n",
      "\n",
      "\t model loss: 0.6934735178947449\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 1 out of 21. Overall error_rate 0.0476190485060215\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.75275797\t0.0003859409\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.89781636\t0.0005317542\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.735037\t0.00081648346\n",
      "\n",
      "\t model loss: 0.7350370287895203\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 2 out of 21. Overall error_rate 0.095238097012043\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.74434465\t0.00051966764\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7096555\t0.0010019311\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.69869953\t0.0006434903\n",
      "\n",
      "\t model loss: 0.6986995339393616\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 3 out of 21. Overall error_rate 0.1428571492433548\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.70890164\t0.00058678805\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7184493\t0.0007377423\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7131918\t0.0007591989\n",
      "\n",
      "\t model loss: 0.7089016437530518\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 5 out of 21. Overall error_rate 0.2380952388048172\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7520493\t0.0007973162\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6879181\t0.0005328424\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6820106\t0.0005085577\n",
      "\n",
      "\t model loss: 0.6820105910301208\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 1 out of 21. Overall error_rate 0.0476190485060215\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.67581123\t0.00034949143\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.68598497\t0.00062234694\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6807564\t0.00049086334\n",
      "\n",
      "\t model loss: 0.675811231136322\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 0 out of 21. Overall error_rate 0.0\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.687917\t0.0005560389\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.67302287\t0.00044898776\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7100709\t0.0010893004\n",
      "\n",
      "\t model loss: 0.6730228662490845\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 0 out of 21. Overall error_rate 0.0\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.66917694\t0.00032411545\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.67278117\t0.00038187316\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.71514016\t0.00072359305\n",
      "\n",
      "\t model loss: 0.6691769361495972\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 0 out of 21. Overall error_rate 0.0\n",
      "smallest_error_rate for 9 hidden_units is 0.0\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.9400724\t0.00053845637\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.87106395\t0.001326346\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8941394\t0.0006809495\n",
      "\n",
      "\t model loss: 0.8710639476776123\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 4 out of 21. Overall error_rate 0.190476194024086\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.83537614\t0.00046677212\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t1.0130824\t0.0005650843\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8396092\t0.001031073\n",
      "\n",
      "\t model loss: 0.8353761434555054\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 2 out of 21. Overall error_rate 0.095238097012043\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8067459\t0.00057565875\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.820608\t0.00046856492\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8806644\t0.00044162938\n",
      "\n",
      "\t model loss: 0.8067458868026733\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 2 out of 21. Overall error_rate 0.095238097012043\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8749802\t0.00053752726\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7133242\t0.00067611964\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8026636\t0.0013178356\n",
      "\n",
      "\t model loss: 0.7133241891860962\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 1 out of 21. Overall error_rate 0.0476190485060215\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.697233\t0.00061316695\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.69500285\t0.00044336298\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7417785\t0.0007910184\n",
      "\n",
      "\t model loss: 0.6950028538703918\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 1 out of 21. Overall error_rate 0.0476190485060215\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6705674\t0.0005049779\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.696267\t0.0004968671\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7536026\t0.0008866359\n",
      "\n",
      "\t model loss: 0.6705673933029175\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 1 out of 21. Overall error_rate 0.0476190485060215\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7715384\t0.0014616746\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.73747283\t0.00085356814\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7469885\t0.0010066946\n",
      "\n",
      "\t model loss: 0.7374728322029114\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 2 out of 21. Overall error_rate 0.095238097012043\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7257951\t0.0005892974\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.70484096\t0.0005949811\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7773927\t0.0011218389\n",
      "\n",
      "\t model loss: 0.7048409581184387\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 1 out of 21. Overall error_rate 0.0476190485060215\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.67999107\t0.0003610084\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.67855394\t0.00054510555\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6749516\t0.00042838245\n",
      "\n",
      "\t model loss: 0.6749516129493713\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 1 out of 21. Overall error_rate 0.0476190485060215\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.74279046\t0.00082334946\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.66887814\t0.00043057886\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6725266\t0.0005085542\n",
      "\n",
      "\t model loss: 0.6688781380653381\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 1 out of 21. Overall error_rate 0.0476190485060215\n",
      "smallest_error_rate for 5 hidden_units is 0.0476190485060215\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.89100426\t0.0005794519\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.84532124\t0.00063293107\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.92561585\t0.00014763497\n",
      "\n",
      "\t model loss: 0.8453212380409241\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 8 out of 21. Overall error_rate 0.380952388048172\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.9008912\t0.00016736152\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8623955\t0.0011120007\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.9668265\t0.00056814967\n",
      "\n",
      "\t model loss: 0.8623955249786377\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 5 out of 21. Overall error_rate 0.2380952388048172\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.81349874\t0.0006935274\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7191551\t0.0006909197\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.81850284\t0.00073292106\n",
      "\n",
      "\t model loss: 0.7191550731658936\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 4 out of 21. Overall error_rate 0.190476194024086\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.74331415\t0.00044211975\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.9026419\t0.0006499417\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.91723067\t0.0005577001\n",
      "\n",
      "\t model loss: 0.7433141469955444\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 3 out of 21. Overall error_rate 0.1428571492433548\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7585525\t0.0006862901\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7676062\t0.0018773081\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7297348\t0.0006974677\n",
      "\n",
      "\t model loss: 0.7297347784042358\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 4 out of 21. Overall error_rate 0.190476194024086\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7086698\t0.0006661102\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.681061\t0.00035143358\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.67104137\t0.0003912059\n",
      "\n",
      "\t model loss: 0.6710413694381714\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 3 out of 21. Overall error_rate 0.1428571492433548\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.68491316\t0.00046241158\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7917891\t0.0005862257\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7037289\t0.0007845373\n",
      "\n",
      "\t model loss: 0.684913158416748\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 3 out of 21. Overall error_rate 0.1428571492433548\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.71531147\t0.0007773347\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6757758\t0.00048416975\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6967089\t0.000784663\n",
      "\n",
      "\t model loss: 0.6757758259773254\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 4 out of 21. Overall error_rate 0.190476194024086\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.72394454\t0.0009216106\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.67234594\t0.0004800846\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.72485447\t0.0019140928\n",
      "\n",
      "\t model loss: 0.6723459362983704\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 4 out of 21. Overall error_rate 0.190476194024086\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7441757\t0.0007061779\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6753571\t0.0007734108\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6973701\t0.00075089326\n",
      "\n",
      "\t model loss: 0.6753571033477783\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 4 out of 21. Overall error_rate 0.190476194024086\n",
      "smallest_error_rate for 5 hidden_units is 0.1428571492433548\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.9664722\t0.00050564273\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.9287873\t0.000695811\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.83658934\t0.0005910734\n",
      "\n",
      "\t model loss: 0.8365893363952637\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 1 out of 21. Overall error_rate 0.0476190485060215\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7128542\t0.0005456184\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.9292511\t0.00023021917\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7972233\t0.0013775942\n",
      "\n",
      "\t model loss: 0.7128542065620422\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 0 out of 21. Overall error_rate 0.0\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.807821\t0.0004416263\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.776158\t0.00083574635\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.85079163\t0.0005807925\n",
      "\n",
      "\t model loss: 0.7761579751968384\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 1 out of 21. Overall error_rate 0.0476190485060215\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.904675\t0.00028355513\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7482617\t0.0008063592\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.97616726\t0.00025693496\n",
      "\n",
      "\t model loss: 0.7482616901397705\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 1 out of 21. Overall error_rate 0.0476190485060215\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7932928\t0.0010684895\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.71075994\t0.0005324817\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.73984706\t0.00075310364\n",
      "\n",
      "\t model loss: 0.7107599377632141\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 1 out of 21. Overall error_rate 0.0476190485060215\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.79830503\t0.0004442773\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7030658\t0.0004819012\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7587964\t0.00094870897\n",
      "\n",
      "\t model loss: 0.703065812587738\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 3 out of 21. Overall error_rate 0.1428571492433548\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.76725495\t0.00061714154\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7486947\t0.0009189055\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6922069\t0.00067961984\n",
      "\n",
      "\t model loss: 0.6922069191932678\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 1 out of 21. Overall error_rate 0.0476190485060215\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7316089\t0.00074067083\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.712954\t0.0008184656\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.69710165\t0.00065128336\n",
      "\n",
      "\t model loss: 0.6971016526222229\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 0 out of 21. Overall error_rate 0.0\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.75055826\t0.001016494\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.67422265\t0.00046126117\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.70426583\t0.0007580816\n",
      "\n",
      "\t model loss: 0.6742226481437683\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 2 out of 21. Overall error_rate 0.095238097012043\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7300303\t0.0007549076\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.68040365\t0.0005094957\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6878031\t0.00062355906\n",
      "\n",
      "\t model loss: 0.6804036498069763\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 1 out of 21. Overall error_rate 0.0476190485060215\n",
      "smallest_error_rate for 3 hidden_units is 0.0\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8352855\t0.0006348293\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.88582593\t0.0010016406\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.9281028\t0.00017003102\n",
      "\n",
      "\t model loss: 0.835285484790802\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 9 out of 21. Overall error_rate 0.4285714328289032\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.88153684\t0.00040173894\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.9078277\t0.0005913451\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.78382003\t0.0013098852\n",
      "\n",
      "\t model loss: 0.7838200330734253\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 3 out of 21. Overall error_rate 0.1428571492433548\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.71359026\t0.0006382461\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.80182785\t0.0003892945\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8549605\t0.0014317317\n",
      "\n",
      "\t model loss: 0.7135902643203735\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 2 out of 21. Overall error_rate 0.095238097012043\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.75236577\t0.0012207598\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8881043\t0.0008700525\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8391986\t0.00267193\n",
      "\n",
      "\t model loss: 0.75236576795578\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 2 out of 21. Overall error_rate 0.095238097012043\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.709247\t0.0007956391\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.71292704\t0.00061904994\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.67892563\t0.00044148957\n",
      "\n",
      "\t model loss: 0.678925633430481\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 2 out of 21. Overall error_rate 0.095238097012043\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.72135675\t0.000617432\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.73049384\t0.0007474223\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8068058\t0.000435391\n",
      "\n",
      "\t model loss: 0.7213567495346069\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 3 out of 21. Overall error_rate 0.1428571492433548\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.72965413\t0.0008772221\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.74800867\t0.001007311\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8031454\t0.0012536081\n",
      "\n",
      "\t model loss: 0.7296541333198547\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 2 out of 21. Overall error_rate 0.095238097012043\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.68099576\t0.00039029986\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6972012\t0.0004920168\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.67909604\t0.0004554972\n",
      "\n",
      "\t model loss: 0.6790960431098938\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 2 out of 21. Overall error_rate 0.095238097012043\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.66592085\t0.00038875715\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6740483\t0.00052304234\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.686508\t0.0005869257\n",
      "\n",
      "\t model loss: 0.6659208536148071\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 2 out of 21. Overall error_rate 0.095238097012043\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6822536\t0.00034095414\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.69797456\t0.0006709375\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.673646\t0.0004422961\n",
      "\n",
      "\t model loss: 0.6736459732055664\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 3 out of 21. Overall error_rate 0.1428571492433548\n",
      "smallest_error_rate for 4 hidden_units is 0.095238097012043\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.9478599\t0.0009274865\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8863914\t0.00088831247\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8661914\t0.00068641314\n",
      "\n",
      "\t model loss: 0.8661913871765137\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 9 out of 21. Overall error_rate 0.4285714328289032\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.75530773\t0.00038321916\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8518075\t0.0006665506\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.93917114\t0.0010038984\n",
      "\n",
      "\t model loss: 0.7553077340126038\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 4 out of 21. Overall error_rate 0.190476194024086\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7732403\t0.0008281234\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7689186\t0.00049338787\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8571218\t0.0009359722\n",
      "\n",
      "\t model loss: 0.7689185738563538\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 5 out of 21. Overall error_rate 0.2380952388048172\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8023249\t0.00053645665\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.77530444\t0.00095546123\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.77441376\t0.00051157165\n",
      "\n",
      "\t model loss: 0.7744137644767761\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 3 out of 21. Overall error_rate 0.1428571492433548\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.71660495\t0.0006089795\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.83334345\t0.0008534191\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.72045696\t0.0006754616\n",
      "\n",
      "\t model loss: 0.7166049480438232\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 3 out of 21. Overall error_rate 0.1428571492433548\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7072495\t0.0005800768\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.74711096\t0.00054778956\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6976107\t0.0009743602\n",
      "\n",
      "\t model loss: 0.6976106762886047\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 2 out of 21. Overall error_rate 0.095238097012043\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6820008\t0.00043670548\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6737427\t0.00041819003\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6920824\t0.00057024363\n",
      "\n",
      "\t model loss: 0.6737427115440369\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 2 out of 21. Overall error_rate 0.095238097012043\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.66693467\t0.00053192145\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7406605\t0.0011621552\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7755657\t0.00042228322\n",
      "\n",
      "\t model loss: 0.6669346690177917\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 2 out of 21. Overall error_rate 0.095238097012043\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7621214\t0.00039753396\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6755334\t0.0005035593\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6871346\t0.00046663708\n",
      "\n",
      "\t model loss: 0.6755334138870239\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 3 out of 21. Overall error_rate 0.1428571492433548\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.66901624\t0.00047909055\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.70486075\t0.0009908484\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7048867\t0.0005992499\n",
      "\n",
      "\t model loss: 0.6690162420272827\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 2 out of 21. Overall error_rate 0.095238097012043\n",
      "smallest_error_rate for 7 hidden_units is 0.095238097012043\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8684969\t0.0007821776\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.92835736\t0.00040650548\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8741752\t0.0004436119\n",
      "\n",
      "\t model loss: 0.8684968948364258\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 3 out of 21. Overall error_rate 0.1428571492433548\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8260908\t0.0004819638\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.91378635\t0.00017471584\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8074332\t0.0010180464\n",
      "\n",
      "\t model loss: 0.8074331879615784\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 1 out of 21. Overall error_rate 0.0476190485060215\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.72679365\t0.00056383153\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7589639\t0.0011965277\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8204905\t0.0010222334\n",
      "\n",
      "\t model loss: 0.726793646812439\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 2 out of 21. Overall error_rate 0.095238097012043\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7416083\t0.00062923913\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.73046947\t0.0007565724\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.80546474\t0.0007245298\n",
      "\n",
      "\t model loss: 0.7304694652557373\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 2 out of 21. Overall error_rate 0.095238097012043\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7331722\t0.0006897348\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.75073135\t0.0013011047\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7132376\t0.0008153872\n",
      "\n",
      "\t model loss: 0.7132375836372375\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 3 out of 21. Overall error_rate 0.1428571492433548\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7492119\t0.0012635876\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7658028\t0.001205189\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.75225276\t0.0010643372\n",
      "\n",
      "\t model loss: 0.7492119073867798\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 2 out of 21. Overall error_rate 0.095238097012043\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.69325197\t0.0004111512\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.67182636\t0.00042062343\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.69513905\t0.0005595154\n",
      "\n",
      "\t model loss: 0.6718263626098633\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 2 out of 21. Overall error_rate 0.095238097012043\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6852266\t0.0004442105\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.67396903\t0.00048643898\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.67407256\t0.000597482\n",
      "\n",
      "\t model loss: 0.673969030380249\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 2 out of 21. Overall error_rate 0.095238097012043\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7137813\t0.0010905599\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6942732\t0.0006962028\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6805558\t0.00041172997\n",
      "\n",
      "\t model loss: 0.6805558204650879\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 3 out of 21. Overall error_rate 0.1428571492433548\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.67708266\t0.0005131366\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6743653\t0.0004599274\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.77774453\t0.00067082036\n",
      "\n",
      "\t model loss: 0.6743652820587158\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 2 out of 21. Overall error_rate 0.095238097012043\n",
      "smallest_error_rate for 3 hidden_units is 0.0476190485060215\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.9060686\t0.000263592\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8410133\t0.00061401573\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8289123\t0.00051609805\n",
      "\n",
      "\t model loss: 0.8289123177528381\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 3 out of 21. Overall error_rate 0.1428571492433548\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.9009812\t0.00053788355\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8461768\t0.0005941599\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8498658\t0.00046876745\n",
      "\n",
      "\t model loss: 0.84617680311203\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 5 out of 21. Overall error_rate 0.2380952388048172\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.833551\t0.0014674532\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.82555014\t0.0006184427\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7774907\t0.0010196483\n",
      "\n",
      "\t model loss: 0.7774906754493713\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 6 out of 21. Overall error_rate 0.2857142984867096\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8121552\t0.0004938956\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7903144\t0.00059507793\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8534952\t0.00066000264\n",
      "\n",
      "\t model loss: 0.7903143763542175\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 3 out of 21. Overall error_rate 0.1428571492433548\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6821195\t0.000428772\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.71066225\t0.0005159656\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.79208493\t0.001709469\n",
      "\n",
      "\t model loss: 0.6821194887161255\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 4 out of 21. Overall error_rate 0.190476194024086\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.77561367\t0.0005031803\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7247156\t0.0010546729\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7079723\t0.00058772607\n",
      "\n",
      "\t model loss: 0.7079722881317139\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 3 out of 21. Overall error_rate 0.1428571492433548\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7262363\t0.0010396081\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6731063\t0.0005229778\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.79227406\t0.001280243\n",
      "\n",
      "\t model loss: 0.67310631275177\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 3 out of 21. Overall error_rate 0.1428571492433548\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.65613824\t0.00035052566\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.68064386\t0.0006226795\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6841906\t0.0004485385\n",
      "\n",
      "\t model loss: 0.6561382412910461\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 2 out of 21. Overall error_rate 0.095238097012043\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6923384\t0.00069926464\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6961438\t0.0005838521\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6933037\t0.0006124325\n",
      "\n",
      "\t model loss: 0.6923384070396423\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 3 out of 21. Overall error_rate 0.1428571492433548\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.66425043\t0.00048315374\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.67281514\t0.00042531645\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6907082\t0.0007262484\n",
      "\n",
      "\t model loss: 0.6642504334449768\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 2 out of 21. Overall error_rate 0.095238097012043\n",
      "smallest_error_rate for 9 hidden_units is 0.095238097012043\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.948193\t0.00088191987\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8838847\t0.0007239283\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t1.020316\t0.00040443824\n",
      "\n",
      "\t model loss: 0.8838847279548645\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 6 out of 20. Overall error_rate 0.30000001192092896\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.74081314\t0.0006861609\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8106961\t0.0006661136\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.88280445\t0.0010991214\n",
      "\n",
      "\t model loss: 0.740813136100769\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 1 out of 20. Overall error_rate 0.05000000074505806\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8755062\t0.0010525003\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.75796753\t0.00045227533\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8836284\t0.000507337\n",
      "\n",
      "\t model loss: 0.7579675316810608\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 2 out of 20. Overall error_rate 0.10000000149011612\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8289394\t0.00041256275\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7452513\t0.0009065421\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.81699014\t0.00088629045\n",
      "\n",
      "\t model loss: 0.7452512979507446\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 1 out of 20. Overall error_rate 0.05000000074505806\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7247487\t0.00071491004\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.684729\t0.0006189669\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7792682\t0.00035026867\n",
      "\n",
      "\t model loss: 0.6847289800643921\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 1 out of 20. Overall error_rate 0.05000000074505806\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.69909513\t0.0004653014\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.72588\t0.0006508194\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6962587\t0.00057828333\n",
      "\n",
      "\t model loss: 0.6962587237358093\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 2 out of 20. Overall error_rate 0.10000000149011612\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.75769925\t0.00064644666\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.70582986\t0.00069560576\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.71972376\t0.00055513857\n",
      "\n",
      "\t model loss: 0.7058298587799072\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 1 out of 20. Overall error_rate 0.05000000074505806\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7656184\t0.0008515939\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.68674713\t0.00057077006\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.72747123\t0.0011041514\n",
      "\n",
      "\t model loss: 0.686747133731842\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 1 out of 20. Overall error_rate 0.05000000074505806\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6822827\t0.00043827083\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7449609\t0.0011299094\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6783176\t0.00043977806\n",
      "\n",
      "\t model loss: 0.6783176064491272\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 1 out of 20. Overall error_rate 0.05000000074505806\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6613926\t0.0005352959\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7031191\t0.0007677813\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7009528\t0.00080963055\n",
      "\n",
      "\t model loss: 0.6613926291465759\n",
      "\n",
      "Number of miss-classifications for ANN:\n",
      "\t 1 out of 20. Overall error_rate 0.05000000074505806\n",
      "smallest_error_rate for 3 hidden_units is 0.05000000074505806\n"
     ]
    }
   ],
   "source": [
    "hidden_units_range = 10\n",
    "initial_hidden_units = 2\n",
    "error_rates_and_hidden_units_in_folds = []\n",
    "for train_index, test_index in CV.split(X_standardized, y):\n",
    "    X_train = torch.from_numpy(X_standardized[train_index]).type(torch.float)\n",
    "    y_train = torch.from_numpy(y[train_index]).type(torch.long)\n",
    "    X_test = torch.from_numpy(X_standardized[test_index]).type(torch.float)\n",
    "    y_test = torch.from_numpy(y[test_index]).type(torch.long)\n",
    "    error_rates_and_hidden_units = []\n",
    "    for n_hidden_units in range(\n",
    "        initial_hidden_units, initial_hidden_units + hidden_units_range\n",
    "    ):\n",
    "        # in the actual code, we would vary the number of hidden_units here\n",
    "        # e.g. for i in range (100) -> calculate mean_error_rate\n",
    "        # Recall that last column represents the classes and should not be used as an input feature\n",
    "        input_features = M - 1\n",
    "        num_epochs = 300\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        seed_model = lambda: torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_features, n_hidden_units),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(n_hidden_units, C),\n",
    "            torch.nn.Softmax(dim=1),\n",
    "        )\n",
    "        net, final_loss, learning_curve = train_neural_net(\n",
    "            seed_model,\n",
    "            loss_fn,\n",
    "            X=X_train,\n",
    "            y=y_train,\n",
    "            n_replicates=3,\n",
    "            max_iter=num_epochs,\n",
    "        )\n",
    "        print(\"\\n\\t model loss: {}\\n\".format(final_loss))\n",
    "\n",
    "        # Determine probability of each class using trained network\n",
    "        softmax_logits = net(X_test)\n",
    "        # convert to label with the highest probability\n",
    "        y_pred = torch.argmax(softmax_logits, dim=1)\n",
    "        # Compare error against ground truth y_test\n",
    "        e = y_pred != y_test\n",
    "        error_rate = sum(e) / len(e)\n",
    "        error_rates_and_hidden_units.append((error_rate, n_hidden_units))\n",
    "        print(\n",
    "            f\"Number of miss-classifications for ANN:\\n\\t {sum(e)} out of {len(e)}. Overall error_rate {error_rate}\"\n",
    "        )\n",
    "\n",
    "    smallest_error_rate, num_hidden_units = min(\n",
    "        error_rates_and_hidden_units, key=itemgetter(0)\n",
    "    )\n",
    "    error_rates_and_hidden_units_in_folds.append(\n",
    "        (smallest_error_rate, num_hidden_units)\n",
    "    )\n",
    "    print(\n",
    "        f\"smallest_error_rate for {num_hidden_units} hidden_units is {smallest_error_rate}\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot comparison table between the 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.6666666666666666),\n",
       " np.float64(0.7142857142857143),\n",
       " np.float64(0.7619047619047619),\n",
       " np.float64(0.7142857142857143),\n",
       " np.float64(0.7142857142857143),\n",
       " np.float64(0.8571428571428571),\n",
       " np.float64(0.8095238095238095),\n",
       " np.float64(0.8095238095238095),\n",
       " np.float64(0.7142857142857143),\n",
       " np.float64(0.75)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_error_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(np.float64(0.047619047619047616), np.float64(9.999999999999999e-06)),\n",
       " (np.float64(0.0), np.float64(0.1)),\n",
       " (np.float64(0.0), np.float64(9.999999999999999e-06)),\n",
       " (np.float64(0.0), np.float64(0.01)),\n",
       " (np.float64(0.047619047619047616), np.float64(0.1)),\n",
       " (np.float64(0.047619047619047616), np.float64(0.01)),\n",
       " (np.float64(0.047619047619047616), np.float64(0.01)),\n",
       " (np.float64(0.047619047619047616), np.float64(9.999999999999999e-06)),\n",
       " (np.float64(0.047619047619047616), np.float64(0.01)),\n",
       " (np.float64(0.0), np.float64(0.1))]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_rates_and_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor(0.0476), 2),\n",
       " (tensor(0.), 9),\n",
       " (tensor(0.0476), 5),\n",
       " (tensor(0.1429), 5),\n",
       " (tensor(0.), 3),\n",
       " (tensor(0.0952), 4),\n",
       " (tensor(0.0952), 7),\n",
       " (tensor(0.0476), 3),\n",
       " (tensor(0.0952), 9),\n",
       " (tensor(0.0500), 3)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_rates_and_hidden_units_in_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([np.float64(0.047619047619047616),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.047619047619047616),\n",
       "  np.float64(0.047619047619047616),\n",
       "  np.float64(0.047619047619047616),\n",
       "  np.float64(0.047619047619047616),\n",
       "  np.float64(0.047619047619047616),\n",
       "  np.float64(0.0)],\n",
       " [0.0476190485060215,\n",
       "  0.0,\n",
       "  0.0476190485060215,\n",
       "  0.1428571492433548,\n",
       "  0.0,\n",
       "  0.095238097012043,\n",
       "  0.095238097012043,\n",
       "  0.0476190485060215,\n",
       "  0.095238097012043,\n",
       "  0.05000000074505806])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import tensor\n",
    "\n",
    "error_rates_from_lambda = [rate for rate, _ in error_rates_and_lambda]\n",
    "lambda_values = [lmbda for _, lmbda in error_rates_and_lambda]\n",
    "\n",
    "error_rates_from_hidden_units = [\n",
    "    rate.item() if hasattr(rate, \"item\") else float(rate)\n",
    "    for rate, _ in error_rates_and_hidden_units_in_folds\n",
    "]\n",
    "hidden_units = [units for _, units in error_rates_and_hidden_units_in_folds]\n",
    "error_rates_from_lambda, error_rates_from_hidden_units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_folds = len(baseline_error_rates)\n",
    "\n",
    "table_data = [\n",
    "    [\n",
    "        fold + 1,\n",
    "        hidden_units[fold],\n",
    "        error_rates_from_hidden_units[fold],\n",
    "        lambda_values[fold],\n",
    "        error_rates_from_lambda[fold],\n",
    "        baseline_error_rates[fold],\n",
    "    ]\n",
    "    for fold in range(num_folds)\n",
    "]\n",
    "\n",
    "# Column headers (as shown in the image)\n",
    "col_labels = [\"i\", \"x_t^*\", \"E_t^NN\", \"λ_t^*\", \"E_t^λ\", \"E_t^baseline\"]\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.axis(\"off\")\n",
    "\n",
    "# Plot the table\n",
    "table = ax.table(\n",
    "    cellText=table_data, colLabels=col_labels, loc=\"center\", cellLoc=\"center\"\n",
    ")\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "table.scale(3, 3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of models using mc neymar test\n",
    "![mc_neymar](museum_of_poor/mc_neymar.png)\n",
    "Perform a statistical evaluation of your three models similar to the previous section. That\n",
    "is, compare the three models pairwise. We will once more allow some freedom in what test\n",
    "to choose. Therefore, choose either:\n",
    "setup I (section 11.3): Use McNemar’s test described in Box 11.3.2)\n",
    "setup II (section 11.4): Use the method described in Box 11.4.1)\n",
    "Include p-values and confidence intervals for the three pairwise tests in your report and\n",
    "conclude on the results: Is one model better than the other? Are the two models better\n",
    "than the baseline? Are some of the models identical? What recommendations would you\n",
    "make based on what you’ve learned?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To ensure a fair comparison, we need to perform the train and test on the same split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.92248374\t0.00069204526\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.92420894\t0.0012064892\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/monkescripts/anaconda3/envs/dtu-ml/lib/python3.11/site-packages/dtuimldmtools/models/nn_trainer.py:141: RuntimeWarning: overflow encountered in cast\n",
      "  if loss_value < best_final_loss:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tFinal loss:\n",
      "\t\t300\t0.9145182\t0.000425809\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7613048\t0.00045138874\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.83934915\t0.00068459276\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.79108906\t0.00093483547\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.93311954\t0.000211962\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8555718\t0.00064532156\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8634081\t0.00084357546\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.76729244\t0.00061858556\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7963031\t0.00039648192\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.71795124\t0.00071081374\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7329912\t0.0010843235\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.709167\t0.00063257123\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.71973443\t0.000868717\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6855402\t0.0006228373\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.75025946\t0.00108595\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7840114\t0.0008961418\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.71171016\t0.00048776437\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.80515575\t0.00073353027\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6846389\t0.0005818313\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.75347525\t0.0006761388\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.66945845\t0.00050777075\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7092949\t0.000925278\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.69256794\t0.00058867014\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6887869\t0.0006090996\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.66043806\t0.00038981895\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6975697\t0.00060519035\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.74355716\t0.0009882952\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.66917455\t0.00065033603\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.86553043\t0.00045918662\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7701104\t0.00045295726\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.9121038\t0.0004465884\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7429312\t0.00075558724\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7170208\t0.0007613729\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8478577\t0.0006925403\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.85093194\t0.00050974725\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7939741\t0.00044309942\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.80544657\t0.0004242953\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.80183095\t0.0008709752\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6993859\t0.00067366974\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.811855\t0.00052158185\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.81271523\t0.00096451835\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.70536214\t0.0006419732\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7686438\t0.0007781805\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7159835\t0.0007999616\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.67952543\t0.0005982974\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.75827724\t0.0005598281\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8183378\t0.0005730383\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6760512\t0.00059335673\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.73071194\t0.0007582763\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6732587\t0.0005108316\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.65871155\t0.00038939362\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.70186573\t0.00066611776\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.67694175\t0.0005087574\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7151492\t0.0008295183\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6704597\t0.0005411151\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.66502154\t0.0004044178\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6475331\t0.00043198242\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.66576535\t0.00048643752\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.89497\t0.00050457026\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t1.0028412\t0.00015130058\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.98004127\t0.00076900556\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.88837284\t0.0006052255\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.85004574\t0.0019310666\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8365829\t0.0007651137\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7314501\t0.0006588063\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.84265435\t0.00042980956\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.75350726\t0.0009597043\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8107224\t0.00049682456\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8673178\t0.00080581405\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.9282712\t0.00065201626\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.77697605\t0.00058804743\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7008922\t0.00069854956\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7196233\t0.0007905434\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.69348836\t0.0006439449\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7430376\t0.0009007528\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7185057\t0.0009787562\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.68465894\t0.000546161\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7531897\t0.00078947307\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.77409565\t0.0004380867\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.69215596\t0.00068560365\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6810049\t0.00052863127\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.66739625\t0.00056857633\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.710853\t0.000599332\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6888634\t0.00092333165\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6750663\t0.00054509786\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6446619\t0.0003227618\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.65442955\t0.00031703577\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6707471\t0.00042121118\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t1.00018\t0.00033802158\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8739818\t0.00024000272\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.9131679\t0.001071081\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8567142\t0.0014095185\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.95827866\t0.00047703064\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.84559864\t0.00051042566\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.74920714\t0.0009340801\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7533478\t0.0010577388\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8699316\t0.0005349644\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7755737\t0.00076655194\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.75389725\t0.0019641465\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7288002\t0.0009966146\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.69929194\t0.0005057884\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6928806\t0.0006562794\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8790254\t0.000597706\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6783429\t0.00048725423\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.692592\t0.00083451776\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7133466\t0.0005872233\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7057656\t0.0008518357\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.75411946\t0.0010395421\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7010626\t0.0006463324\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6839344\t0.0005645851\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7144972\t0.0007196621\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.680183\t0.00061032287\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.70403856\t0.0006633024\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6905582\t0.000609952\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.67515594\t0.00042437174\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.66133946\t0.0004524138\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.66945547\t0.00051568897\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.67424333\t0.0004517083\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.9426061\t0.00024971148\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7764836\t0.00059539726\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8722682\t0.0006196688\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7955491\t0.0007830024\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.860743\t0.00071986736\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t1.0398024\t0.00030761547\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7207661\t0.00076328206\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7917289\t0.00061130984\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7865064\t0.0010047953\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8754899\t0.0010281975\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.86490893\t0.0012213229\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7547975\t0.00090643787\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7322149\t0.00085684797\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.72655\t0.0008094686\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.78320485\t0.00055471505\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.75198764\t0.0009951043\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8228722\t0.001223014\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.79218286\t0.0005212237\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.680025\t0.0004439288\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.74281085\t0.0010173155\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.71611\t0.0009679882\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.67566055\t0.00049473986\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7575012\t0.0006356137\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.74142486\t0.00083786657\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6951436\t0.0007346321\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6747227\t0.00043170524\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.68828297\t0.0005555704\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6576369\t0.00029818946\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.67518866\t0.00048168024\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6970662\t0.0006712989\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t1.055458\t0.0006011864\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.9319565\t0.0007536701\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.96175206\t0.000349603\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.84380496\t0.0002765417\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.80324394\t0.0007803231\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7184285\t0.0007966615\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.92070943\t0.0015822722\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8170081\t0.0013356935\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8384092\t0.0007069418\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7879715\t0.0015312409\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.82285964\t0.0013975796\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.78981155\t0.00031950028\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6933756\t0.00051156187\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7169383\t0.0009991479\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.76274014\t0.00035410773\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.72820985\t0.0006809449\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.70791\t0.0005528754\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.78259957\t0.00045996142\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7809302\t0.0005786678\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.75742567\t0.0007691113\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.75621885\t0.00048812604\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.661714\t0.0004575575\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.70543337\t0.0006173518\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7783652\t0.0004612384\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6660723\t0.00032705654\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6727725\t0.0004838518\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.66144913\t0.0003041263\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.68275946\t0.00045401373\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7391461\t0.00058590836\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6889119\t0.0005148747\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.86233544\t0.00062576646\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.85752255\t0.0003995111\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.9110586\t0.0005591236\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.85914516\t0.0004947577\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.9924547\t0.0009387822\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.79105145\t0.0011719539\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8368938\t0.0005730739\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.76306695\t0.000502788\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.787842\t0.000991617\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7401321\t0.00092494464\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.81091356\t0.0005790158\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.75304854\t0.00066031737\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7110622\t0.00063331414\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8317113\t0.0005409218\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.690983\t0.0004986828\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.71996874\t0.00075263676\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7011663\t0.00046265367\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.75024545\t0.000658419\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6954124\t0.000681625\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.69091624\t0.0004483114\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6944536\t0.0006992791\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6802572\t0.0005676353\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.76043516\t0.00077029597\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.68140644\t0.0004590223\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.68940055\t0.0007413517\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6873754\t0.000527286\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.72753704\t0.0008027275\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6891415\t0.00049716333\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7425351\t0.0014213568\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6903719\t0.00045996462\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.97412664\t0.0003072518\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.91874486\t0.00029892486\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t1.1036698\t0.00036656542\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.90604603\t0.0006034802\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8150221\t0.00048835995\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.83254665\t0.00063734537\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.9178849\t0.0004635647\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8329257\t0.0005640799\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8242618\t0.0010663427\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7644038\t0.00048126598\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.80601925\t0.0005751433\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.75328475\t0.0006092968\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.70086575\t0.0007016332\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7566534\t0.00067825674\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7328145\t0.00070915866\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7509378\t0.0012697129\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6847707\t0.00056363514\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7135564\t0.00065087347\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.70819914\t0.0007521097\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7268365\t0.0009362823\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7101735\t0.0006886721\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.69679165\t0.00063243625\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.76000303\t0.0008183414\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7186789\t0.0009977238\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6886135\t0.000575449\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7034073\t0.00069791515\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.69625086\t0.00053903967\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6760842\t0.00044942193\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8149776\t0.0005382876\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.70933807\t0.00060858426\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.903453\t0.00017011867\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.90861607\t0.00036754934\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.81936693\t0.00046251534\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8499623\t0.00054528454\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7924894\t0.00050471793\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8512115\t0.0005621111\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8484556\t0.0007874524\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.67766994\t0.0004680547\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.768364\t0.00044569344\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8010927\t0.00055541616\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7819562\t0.00044647933\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7402425\t0.0015967431\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7015888\t0.0009528996\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.74095196\t0.00093885674\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.72310597\t0.0006664033\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8457308\t0.000602709\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.78985125\t0.0006652174\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.817605\t0.00063049194\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6580268\t0.0003095096\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6721131\t0.00047883324\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6936701\t0.00079470366\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.76966614\t0.0010333267\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.69919246\t0.00058054156\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6672005\t0.00035819606\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.67019695\t0.0003905433\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.69532543\t0.000609283\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6845243\t0.0005748838\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.67097956\t0.0004687258\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.71383876\t0.0010798076\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.670988\t0.00036673815\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.91252726\t0.00061961624\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.9390191\t0.0002249698\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.94254184\t0.0005777264\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8448703\t0.0005739382\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.93171996\t0.0002147742\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.86235255\t0.00072383916\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8504129\t0.00086233247\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8321328\t0.00064252666\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7394896\t0.0010100554\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7624551\t0.0009574252\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7662397\t0.00054601044\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.8164407\t0.00076859456\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7551969\t0.00091588544\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.71254194\t0.00074301875\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.82366675\t0.0011892054\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7077694\t0.0010045144\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.73712337\t0.0008828705\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.71146446\t0.00070273335\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6880119\t0.0004979792\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.69856447\t0.0006662812\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7566439\t0.0015612431\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.669042\t0.00036228495\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.68372554\t0.0005080666\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7653173\t0.0007065157\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7209996\t0.0007510662\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7040328\t0.00083812553\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.67317337\t0.00037510355\n",
      "\n",
      "\tReplicate: 1/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.7012391\t0.0008098943\n",
      "\n",
      "\tReplicate: 2/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.6911149\t0.0007910953\n",
      "\n",
      "\tReplicate: 3/3\n",
      "\t\tIter\tLoss\t\t\tRel. loss\n",
      "\t\tFinal loss:\n",
      "\t\t300\t0.68495536\t0.0005053293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((209,), (209,), (209,), (209,))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_dummy = []\n",
    "yhat_log = []\n",
    "yhat_ann = []\n",
    "y_true = []\n",
    "lambdas = np.power(10.0, range(-5, 5))\n",
    "for train_index, test_index in CV.split(X_standardized, y):\n",
    "    X_train = X_standardized[train_index]\n",
    "    y_train = y[train_index].astype(np.int64)\n",
    "    X_test = X_standardized[test_index]\n",
    "    y_test = y[test_index].astype(np.int64)\n",
    "    internal_cross_validation = 10\n",
    "    input_features = M - 1\n",
    "    y_true.append(y_test)\n",
    "\n",
    "    # One-hot encoding\n",
    "    Y_train_hot = np.zeros((len(y_train), C))\n",
    "    for i, label in enumerate(y_train):\n",
    "        Y_train_hot[i, label] = 1\n",
    "\n",
    "    # Dummy classifier\n",
    "    baseline = DummyClassifier(strategy='most_frequent')\n",
    "    baseline.fit(X_train, y_train)\n",
    "    y_dummy_pred = baseline.predict(X_test)\n",
    "    yhat_dummy.append(y_dummy_pred)\n",
    "    (\n",
    "        _,\n",
    "        opt_lambda,\n",
    "        _,\n",
    "        _,\n",
    "        _,\n",
    "    ) = rlr_validate(X_train, y_train, lambdas, internal_cross_validation)\n",
    "    Xty = X_train.T @ Y_train_hot\n",
    "    XtX = X_train.T @ X_train\n",
    "    # Estimate weights for the optimal value of lambda, on entire training set\n",
    "    lambdaI = opt_lambda * np.eye(input_features)\n",
    "    lambdaI[0, 0] = 0  # Do no regularize the bias term\n",
    "    # Recall: Introduce regularization term λ‖w‖2 to penalize large weights, remove the significance of these weight\n",
    "    # Recall: (X^T@X + lambdaI) @ w = X^T @ y\n",
    "    estimated_weights = np.linalg.solve(XtX + lambdaI, Xty).squeeze()\n",
    "    prediction_logits = X_test @ estimated_weights\n",
    "    predicted_class = np.argmax(softmax(prediction_logits), axis=1)\n",
    "    yhat_log.append(predicted_class)\n",
    "\n",
    "    X_train_tensor = torch.from_numpy(X_standardized[train_index]).type(torch.float)\n",
    "    y_train_tensor = torch.from_numpy(y[train_index]).type(torch.long)\n",
    "    X_test_tensor = torch.from_numpy(X_standardized[test_index]).type(torch.float)\n",
    "    y_test_tensor = torch.from_numpy(y[test_index]).type(torch.long)\n",
    "    error_rates_and_hidden_units = []\n",
    "    input_features = M - 1\n",
    "    num_epochs = 300\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    seed_model = lambda: torch.nn.Sequential(\n",
    "        torch.nn.Linear(input_features, n_hidden_units),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(n_hidden_units, C),\n",
    "        torch.nn.Softmax(dim=1),\n",
    "    )\n",
    "    for n_hidden_units in range(\n",
    "        initial_hidden_units, initial_hidden_units + hidden_units_range\n",
    "    ):\n",
    "        # in the actual code, we would vary the number of hidden_units here\n",
    "        # e.g. for i in range (100) -> calculate mean_error_rate\n",
    "        # Recall that last column represents the classes and should not be used as an input feature\n",
    "\n",
    "        net, final_loss, learning_curve = train_neural_net(\n",
    "            seed_model,\n",
    "            loss_fn,\n",
    "            X=X_train_tensor,\n",
    "            y=y_train_tensor,\n",
    "            n_replicates=3,\n",
    "            max_iter=num_epochs,\n",
    "        )\n",
    "\n",
    "        # Determine probability of each class using trained network\n",
    "        softmax_logits = net(X_test_tensor)\n",
    "        # convert to label with the highest probability\n",
    "        y_pred = torch.argmax(softmax_logits, dim=1)\n",
    "        # Compare error against ground truth y_test\n",
    "        e = y_pred != y_test_tensor\n",
    "        error_rate = sum(e) / len(e)\n",
    "        error_rates_and_hidden_units.append((error_rate, n_hidden_units, y_pred))\n",
    "\n",
    "\n",
    "    _, _, best_pred = min(\n",
    "        error_rates_and_hidden_units, key=itemgetter(0)\n",
    "    )\n",
    "    yhat_ann.append(best_pred)\n",
    "yhat_dummy = np.concatenate(yhat_dummy)\n",
    "yhat_log = np.concatenate(yhat_log)\n",
    "yhat_ann = np.concatenate(yhat_ann)\n",
    "y_true = np.concatenate(y_true)\n",
    "yhat_dummy.shape, yhat_log.shape, yhat_ann.shape, y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0,\n",
       "        0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 0, 1, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 0, 0,\n",
       "        0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2]),\n",
       " array([0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0,\n",
       "        0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0,\n",
       "        2, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0,\n",
       "        0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 0, 1, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0,\n",
       "        2, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 2, 0, 2, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2])]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhats = [yhat_dummy, yhat_log, yhat_ann]\n",
    "yhats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of McNemars test using alpha= 0.05\n",
      "Comparison matrix n\n",
      "[[ 49.   1.]\n",
      " [154.   5.]]\n",
      "Approximate 1-alpha confidence interval of theta: [thetaL,thetaU] =  (np.float64(-0.7903905658158767), np.float64(-0.6678610318907889))\n",
      "p-value for two-sided test A and B have same accuracy (exact binomial test): p= 6.831330013583483e-45\n",
      "\n",
      "Comparison: Dummy (A) vs Logistic (B)\n",
      "theta = theta_A - theta_B point estimate: -0.7321\n",
      "CI (Jeffreys, 95%): (np.float64(-0.7903905658158767), np.float64(-0.6678610318907889))\n",
      "p-value: 0.0000\n",
      "-> Significant difference (p < 0.05)\n",
      "Result of McNemars test using alpha= 0.05\n",
      "Comparison matrix n\n",
      "[[ 45.   5.]\n",
      " [153.   6.]]\n",
      "Approximate 1-alpha confidence interval of theta: [thetaL,thetaU] =  (np.float64(-0.7730079737018365), np.float64(-0.6367254737946959))\n",
      "p-value for two-sided test A and B have same accuracy (exact binomial test): p= 4.353903019651069e-39\n",
      "\n",
      "Comparison: Dummy (A) vs ANN (B)\n",
      "theta = theta_A - theta_B point estimate: -0.7081\n",
      "CI (Jeffreys, 95%): (np.float64(-0.7730079737018365), np.float64(-0.6367254737946959))\n",
      "p-value: 0.0000\n",
      "-> Significant difference (p < 0.05)\n",
      "Result of McNemars test using alpha= 0.05\n",
      "Comparison matrix n\n",
      "[[195.   8.]\n",
      " [  3.   3.]]\n",
      "Approximate 1-alpha confidence interval of theta: [thetaL,thetaU] =  (np.float64(-0.006945579394251111), np.float64(0.05476998164478264))\n",
      "p-value for two-sided test A and B have same accuracy (exact binomial test): p= 0.2265625\n",
      "\n",
      "Comparison: Logistic (A) vs ANN (B)\n",
      "theta = theta_A - theta_B point estimate: 0.0239\n",
      "CI (Jeffreys, 95%): (np.float64(-0.006945579394251111), np.float64(0.05476998164478264))\n",
      "p-value: 0.2266\n",
      "-> No significant difference (p >= 0.05)\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from dtuimldmtools import mcnemar\n",
    "\n",
    "model_names = [\"Dummy\", \"Logistic\", \"ANN\"]\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "for i, j in itertools.combinations(range(len(yhats)), 2):\n",
    "    yhat_A = yhats[i]\n",
    "    yhat_B = yhats[j]\n",
    "    model_A = model_names[i]\n",
    "    model_B = model_names[j]\n",
    "\n",
    "    # Compute McNemar's test with Jeffreys interval\n",
    "    [thetahat, CI, p] = mcnemar(y_true, yhat_A, yhat_B, alpha=alpha)\n",
    "\n",
    "    print(f\"\\nComparison: {model_A} (A) vs {model_B} (B)\")\n",
    "    print(f\"theta = theta_A - theta_B point estimate: {thetahat:.4f}\")\n",
    "    print(f\"CI (Jeffreys, {1-alpha:.0%}): {CI}\")\n",
    "    print(f\"p-value: {p:.4f}\")\n",
    "    if p < alpha:\n",
    "        print(f\"-> Significant difference (p < {alpha})\")\n",
    "    else:\n",
    "        print(f\"-> No significant difference (p >= {alpha})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final regression model with $\\lambda$ = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of miss-classifications for logic regression model with optimal lambda value 0.01:\n",
      "\t 0 out of 21. Overall error_rate 0.0\n",
      "Number of miss-classifications for logic regression model with optimal lambda value 0.01:\n",
      "\t 0 out of 21. Overall error_rate 0.0\n",
      "Number of miss-classifications for logic regression model with optimal lambda value 0.01:\n",
      "\t 0 out of 21. Overall error_rate 0.0\n",
      "Number of miss-classifications for logic regression model with optimal lambda value 0.01:\n",
      "\t 0 out of 21. Overall error_rate 0.0\n",
      "Number of miss-classifications for logic regression model with optimal lambda value 0.01:\n",
      "\t 0 out of 21. Overall error_rate 0.0\n",
      "Number of miss-classifications for logic regression model with optimal lambda value 0.01:\n",
      "\t 1 out of 21. Overall error_rate 0.047619047619047616\n",
      "Number of miss-classifications for logic regression model with optimal lambda value 0.01:\n",
      "\t 1 out of 21. Overall error_rate 0.047619047619047616\n",
      "Number of miss-classifications for logic regression model with optimal lambda value 0.01:\n",
      "\t 1 out of 21. Overall error_rate 0.047619047619047616\n",
      "Number of miss-classifications for logic regression model with optimal lambda value 0.01:\n",
      "\t 0 out of 21. Overall error_rate 0.0\n",
      "Number of miss-classifications for logic regression model with optimal lambda value 0.01:\n",
      "\t 3 out of 20. Overall error_rate 0.15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([np.float64(0.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.047619047619047616),\n",
       "  np.float64(0.047619047619047616),\n",
       "  np.float64(0.047619047619047616),\n",
       "  np.float64(0.0),\n",
       "  np.float64(0.15)],\n",
       " 10)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_rates = []\n",
    "for train_index, test_index in CV.split(X_standardized, y):\n",
    "    X_train = X_standardized[train_index]\n",
    "    y_train = y[train_index].astype(np.int64)\n",
    "    X_test = X_standardized[test_index]\n",
    "    y_test = y[test_index].astype(np.int64)\n",
    "    internal_cross_validation = 10\n",
    "    input_features = M - 1\n",
    "    # One-hot encoding\n",
    "    Y_train = np.zeros((len(y_train), C))\n",
    "    for i, label in enumerate(y_train):\n",
    "        Y_train[i, label] = 1\n",
    "    opt_lambda = 0.01\n",
    "    Xty = X_train.T @ Y_train\n",
    "    XtX = X_train.T @ X_train\n",
    "    # Estimate weights for the optimal value of lambda, on entire training set\n",
    "    lambdaI = opt_lambda * np.eye(input_features)\n",
    "    lambdaI[0, 0] = 0  # Do no regularize the bias term\n",
    "    # Recall: Introduce regularization term λ‖w‖2 to penalize large weights, remove the significance of these weight\n",
    "    # Recall: (X^T@X + lambdaI) @ w = X^T @ y\n",
    "    estimated_weights = np.linalg.solve(XtX + lambdaI, Xty).squeeze()\n",
    "    prediction_logits = X_test @ estimated_weights\n",
    "    predicted_classes = np.argmax(softmax(prediction_logits), axis=1)\n",
    "    e = predicted_classes != y_test\n",
    "    error_rate = sum(e) / len(e)\n",
    "    error_rates.append(error_rate)\n",
    "    print(\n",
    "        f\"Number of miss-classifications for logic regression model with optimal lambda value {opt_lambda}:\\n\\t {sum(e)} out of {len(e)}. Overall error_rate {error_rate}\"\n",
    "    )\n",
    "error_rates, len(error_rates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtu-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
